# ğŸ¤– RAG Chatbot dengan Ollama + LangChain

Proyek ini membangun **chatbot lokal berbasis Retrieval-Augmented Generation (RAG)** menggunakan **Ollama**, **LangChain**, dan **ChromaDB**.  
Chatbot ini dapat menjawab pertanyaan berdasarkan isi dokumen teks lokal.

---

## ğŸš€ Fitur Utama

- ğŸ” **Retrieval-Augmented Generation (RAG)** untuk jawaban berbasis konteks dokumen.  
- ğŸ§  **Ollama LLM (Llama3)** berjalan lokal tanpa koneksi API eksternal.  
- ğŸ“š **ChromaDB** sebagai penyimpanan *vector embeddings* dokumen.  
- ğŸ§© **LangChain** sebagai kerangka kerja pipeline RAG.  
- ğŸ’¬ **Streamlit UI** yang interaktif untuk tanya jawab langsung.

---

## ğŸ§° Teknologi yang Digunakan

| Komponen | Deskripsi |
|-----------|------------|
| ğŸ¦™ Ollama | Local LLM engine (model: `llama3` dan `mxbai-embed-large`) |
| ğŸ§  LangChain | Framework RAG pipeline |
| ğŸ§© LangChain-Chroma | Vector store integration |
| ğŸ’¾ ChromaDB | Penyimpanan embeddings dokumen |
| ğŸª„ Streamlit | Antarmuka pengguna interaktif |
| ğŸ Python 3.10+ | Bahasa utama |

---

## Screenshot DEMO


---

âš™ï¸ Cara Menjalankan
1ï¸âƒ£ Persiapan

Pastikan kamu sudah menginstall Ollama dan menjalankan server-nya:

ollama serve

Kemudian download model yang dibutuhkan:

ollama pull llama3
ollama pull mxbai-embed-large
2ï¸âƒ£ Install Dependensi

Aktifkan virtual environment dan install semua library yang dibutuhkan:

pip install -r requirements.txt
3ï¸âƒ£ Jalankan Aplikasi

Jalankan proyek dengan perintah berikut:

streamlit run app.py

Lalu copy ip address localhost ke browser